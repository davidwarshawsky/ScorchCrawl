# =============================================================================
# ScorchCrawl Configuration
# Copy this file to .env and fill in your values
# =============================================================================

# === REQUIRED ===
# GitHub Personal Access Token with 'copilot' scope
# Get one at: https://github.com/settings/tokens
# Required for the Copilot SDK agent engine
GITHUB_TOKEN=ghp_your_token_here

# === Reverse Proxy Mode ===
# Set to true to allow remote clients to connect to this server
# When false, only localhost connections are accepted (MCP over stdio or local HTTP)
ENABLE_REVERSE_PROXY=false

# === Network Binding ===
# MCP Server (the endpoint your client connects to)
MCP_PORT=24787
MCP_HOST=127.0.0.1
# To expose remotely: MCP_HOST=0.0.0.0

# ScorchCrawl API (internal, optionally exposed for direct API access)
SCORCHCRAWL_PORT=24786
SCORCHCRAWL_HOST=127.0.0.1
INTERNAL_PORT=3002

# === Copilot Agent Configuration ===
COPILOT_AGENT_MODELS=gpt-4.1,gpt-4o,gpt-5-mini
COPILOT_AGENT_DEFAULT_MODEL=gpt-4.1

# === Authentication ===
USE_DB_AUTHENTICATION=false
BULL_AUTH_KEY=scorchcrawl-admin

# === Rate Limiting ===
RATE_LIMIT_MAX_GLOBAL_CONCURRENCY=10
RATE_LIMIT_MAX_PER_USER_CONCURRENCY=3

# === Scraping Configuration ===
SCRAPE_MAX_ATTEMPTS=6
SCRAPE_MAX_PDF_PREFETCHES=2
SCRAPE_MAX_DOCUMENT_PREFETCHES=2
SCRAPE_MAX_FEATURE_TOGGLES=3

# === Concurrency ===
NUM_WORKERS_PER_QUEUE=16
MAX_CONCURRENT_JOBS=10
CRAWL_CONCURRENT_REQUESTS=20
BROWSER_POOL_SIZE=10

# === Playwright Backend ===
PLAYWRIGHT_MICROSERVICE_URL=http://playwright:3000/scrape

# === Optional: Residential IP Proxy ===
# Uncomment to route scraping through a proxy
# PROXY_SERVER=http://proxy:8080
# PROXY_USERNAME=
# PROXY_PASSWORD=

# === Optional: SearxNG Integration ===
# SEARXNG_ENDPOINT=http://host.docker.internal:8080

# === Logging ===
LOGGING_LEVEL=info
